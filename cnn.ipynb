{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8pXL1oX-5k4S"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# sklearn\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "brHnWmNQ5iUL"
   },
   "outputs": [],
   "source": [
    "# run data_processing.ipynb to generate the train, val, test sets here\n",
    "# load and split train, val, test, (X, y)\n",
    "TRAIN_DATA = 'data/training.1440000.csv'\n",
    "VAL_DATA = 'data/validation.80000.csv'\n",
    "TEST_DATA = 'data/test.80000.csv'\n",
    "\n",
    "df_train = pd.read_csv(TRAIN_DATA)\n",
    "df_val = pd.read_csv(VAL_DATA)\n",
    "df_test = pd.read_csv(TEST_DATA)\n",
    "\n",
    "X_train, y_train = df_train['text'], df_train['target']\n",
    "X_val, y_val = df_val['text'], df_val['target']\n",
    "X_test, y_test = df_test['text'], df_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.9.1-cp39-cp39-macosx_10_14_x86_64.whl (228.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 228.5 MB 30 kB/s s eta 0:00:01   |█▍                              | 10.1 MB 3.2 MB/s eta 0:01:09\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting flatbuffers<2,>=1.12\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting keras<2.10.0,>=2.9.0rc0\n",
      "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 16.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /Users/kevinchen/opt/miniconda3/envs/nlu/lib/python3.9/site-packages (from tensorflow) (3.2.1)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
      "\u001b[K     |████████████████████████████████| 123 kB 17.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp39-cp39-macosx_10_14_x86_64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 17.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/kevinchen/opt/miniconda3/envs/nlu/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.1-py2.py3-none-macosx_10_9_x86_64.whl (13.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.2 MB 19.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 4.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /Users/kevinchen/opt/miniconda3/envs/nlu/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 9.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 7.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.46.3-cp39-cp39-macosx_10_10_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 53.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp39-cp39-macosx_10_9_x86_64.whl (961 kB)\n",
      "\u001b[K     |████████████████████████████████| 961 kB 10.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "\u001b[K     |████████████████████████████████| 438 kB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/kevinchen/opt/miniconda3/envs/nlu/lib/python3.9/site-packages (from tensorflow) (1.20.3)\n",
      "Requirement already satisfied: packaging in /Users/kevinchen/opt/miniconda3/envs/nlu/lib/python3.9/site-packages (from tensorflow) (21.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/kevinchen/opt/miniconda3/envs/nlu/lib/python3.9/site-packages (from tensorflow) (3.10.0.2)\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "  Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 3.4 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /Users/kevinchen/opt/miniconda3/envs/nlu/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/kevinchen/opt/miniconda3/envs/nlu/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/kevinchen/opt/miniconda3/envs/nlu/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.26.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\n",
      "\u001b[K     |████████████████████████████████| 156 kB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /Users/kevinchen/opt/miniconda3/envs/nlu/lib/python3.9/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.2)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 6.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/kevinchen/opt/miniconda3/envs/nlu/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/kevinchen/opt/miniconda3/envs/nlu/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.6.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kevinchen/opt/miniconda3/envs/nlu/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kevinchen/opt/miniconda3/envs/nlu/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/kevinchen/opt/miniconda3/envs/nlu/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/kevinchen/opt/miniconda3/envs/nlu/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /Users/kevinchen/opt/miniconda3/envs/nlu/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.1.0 astunparse-1.6.3 cachetools-5.2.0 flatbuffers-1.12 gast-0.4.0 google-auth-2.6.6 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.46.3 keras-2.9.0 keras-preprocessing-1.1.2 libclang-14.0.1 markdown-3.3.7 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.9.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "m7fmHR8i59om"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "max_words=10000\n",
    "tokenizer=Tokenizer(max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequence_train=tokenizer.texts_to_sequences(X_train)\n",
    "sequence_val=tokenizer.texts_to_sequences(X_val)\n",
    "sequence_test=tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDAAWF_V6i8M",
    "outputId": "112969df-be04-4040-a99c-e6dffb05fab2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 277457 number of independent tokens\n"
     ]
    }
   ],
   "source": [
    "word2vec=tokenizer.word_index\n",
    "V=len(word2vec)\n",
    "print('dataset has %s number of independent tokens' %V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FLie7Iuy6lSR",
    "outputId": "70f8b103-71b5-44cc-88c7-6f8087857209"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440000, 116)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "data_train=pad_sequences(sequence_train)\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ShdJG1zV6n42",
    "outputId": "b3479b05-8ddb-4543-f491-2b5b05962ff2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 116)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T=data_train.shape[1]\n",
    "data_test=pad_sequences(sequence_test,maxlen=T)\n",
    "data_test.shape\n",
    "data_val=pad_sequences(sequence_val,maxlen=T)\n",
    "data_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_0v3hkyW6qJV"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input,Conv1D,MaxPooling1D,Dense,GlobalMaxPooling1D,Embedding\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dv7AfMlk6sUl",
    "outputId": "350aa783-0dd4-4636-b940-41212b661f9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 116)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 116, 20)           5549160   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 114, 32)           1952      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 38, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 36, 64)            6208      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 12, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 10, 128)           24704     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,582,669\n",
      "Trainable params: 5,582,669\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-06 15:00:09.612205: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "D=20\n",
    "i=Input((T,))\n",
    "x=Embedding(V+1,D)(i)\n",
    "x=Conv1D(32,3,activation='relu')(x)\n",
    "x=MaxPooling1D(3)(x)\n",
    "x=Conv1D(64,3,activation='relu')(x)\n",
    "x=MaxPooling1D(3)(x)\n",
    "x=Conv1D(128,3,activation='relu')(x)\n",
    "x=GlobalMaxPooling1D()(x)\n",
    "x=Dense(5,activation='softmax')(x)\n",
    "model=Model(i,x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FQhx-8cZ6vJV",
    "outputId": "3fa3f7a3-2e12-4f97-9def-c5d37b564a8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "14400/14400 [==============================] - 623s 43ms/step - loss: 0.4187 - accuracy: 0.8058 - val_loss: 0.3949 - val_accuracy: 0.8206\n",
      "Epoch 2/5\n",
      "14400/14400 [==============================] - 615s 43ms/step - loss: 0.3803 - accuracy: 0.8287 - val_loss: 0.3851 - val_accuracy: 0.8265\n",
      "Epoch 3/5\n",
      "14400/14400 [==============================] - 618s 43ms/step - loss: 0.3659 - accuracy: 0.8367 - val_loss: 0.3885 - val_accuracy: 0.8257\n",
      "Epoch 4/5\n",
      "14400/14400 [==============================] - 606s 42ms/step - loss: 0.3558 - accuracy: 0.8422 - val_loss: 0.3879 - val_accuracy: 0.8253\n",
      "Epoch 5/5\n",
      "14400/14400 [==============================] - 613s 43ms/step - loss: 0.3480 - accuracy: 0.8463 - val_loss: 0.3893 - val_accuracy: 0.8239\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "cnn_senti=model.fit(data_train,y_train,validation_data=(data_val,y_val),epochs=5,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "aRnvDQJkAws0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 3s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(data_test)\n",
    "y_pred=np.argmax(y_pred,axis=1)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred).to_csv('predictions/cnn.pred.80000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83     40146\n",
      "           1       0.84      0.82      0.83     39854\n",
      "\n",
      "    accuracy                           0.83     80000\n",
      "   macro avg       0.83      0.83      0.83     80000\n",
      "weighted avg       0.83      0.83      0.83     80000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
